{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12458011,"sourceType":"datasetVersion","datasetId":7858693}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ✅ Step 1: Import Libraries\nimport os\nimport shutil\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom collections import Counter\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms, datasets, models\nfrom torch.utils.data import DataLoader, random_split\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# ✅ Step 2: Define Dataset Paths and Combine Original + Augmented Data\nbase_dir = \"/kaggle/input/classification-of-rice-varieties-in-bangladesh/An Extensive Image Dataset for Classifying Rice Varieties in Bangladesh\"\noriginal_dir = os.path.join(base_dir, \"Original\", \"Original\")\naugmented_dir = os.path.join(base_dir, \"Augmented\", \"Augmented\")\ncombined_path = \"/kaggle/working/train_data\"\n\nif os.path.exists(combined_path):\n    shutil.rmtree(combined_path)\nos.makedirs(combined_path)\n\n# Merge all images from Original and Augmented into one folder per class\nfor class_name in os.listdir(original_dir):\n    orig_class = os.path.join(original_dir, class_name)\n    aug_class = os.path.join(augmented_dir, class_name)\n    target_class = os.path.join(combined_path, class_name)\n    os.makedirs(target_class, exist_ok=True)\n\n    for file in os.listdir(orig_class):\n        shutil.copy(os.path.join(orig_class, file), os.path.join(target_class, file))\n    for file in os.listdir(aug_class):\n        shutil.copy(os.path.join(aug_class, file), os.path.join(target_class, file))\n\n# ✅ Step 3: Transforms and Load Dataset\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n\ndataset = datasets.ImageFolder(combined_path, transform=transform)\nclass_names = dataset.classes\nnum_classes = len(class_names)\nprint(\"Classes:\", class_names)\n\n# ✅ Step 4: Split into Train and Validation Sets\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n# ✅ Step 5: Load Pretrained ResNet50\nmodel = models.resnet50(pretrained=True)\nfor param in model.parameters():\n    param.requires_grad = False  # freeze all layers\n\nmodel.fc = nn.Sequential(\n    nn.Linear(model.fc.in_features, 512),\n    nn.ReLU(),\n    nn.Dropout(0.4),\n    nn.Linear(512, num_classes)\n)\n\nmodel = model.to(device)\n\n# ✅ Step 6: Define Loss and Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n\n# ✅ Step 7: Training Loop\ntrain_acc, val_acc = [], []\ntrain_loss, val_loss = [], []\n\nepochs = 10\nfor epoch in range(epochs):\n    model.train()\n    running_loss, running_correct = 0.0, 0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item() * images.size(0)\n        _, preds = torch.max(outputs, 1)\n        running_correct += torch.sum(preds == labels)\n\n    epoch_loss = running_loss / len(train_loader.dataset)\n    epoch_acc = running_correct.double() / len(train_loader.dataset)\n    train_loss.append(epoch_loss)\n    train_acc.append(epoch_acc.item())\n\n    # Validation\n    model.eval()\n    val_running_loss, val_running_correct = 0.0, 0\n\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            val_running_loss += loss.item() * images.size(0)\n            _, preds = torch.max(outputs, 1)\n            val_running_correct += torch.sum(preds == labels)\n\n    val_epoch_loss = val_running_loss / len(val_loader.dataset)\n    val_epoch_acc = val_running_correct.double() / len(val_loader.dataset)\n    val_loss.append(val_epoch_loss)\n    val_acc.append(val_epoch_acc.item())\n\n    print(f\"Epoch {epoch+1}/{epochs} | \"\n          f\"Train Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f} | \"\n          f\"Val Loss: {val_epoch_loss:.4f}, Acc: {val_epoch_acc:.4f}\")\n\n# ✅ Step 8: Plot Accuracy and Loss Curves\nplt.figure(figsize=(14, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(train_acc, label='Train Acc')\nplt.plot(val_acc, label='Val Acc')\nplt.title(\"Accuracy over Epochs\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(train_loss, label='Train Loss')\nplt.plot(val_loss, label='Val Loss')\nplt.title(\"Loss over Epochs\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n# ✅ Step 9: Confusion Matrix + Classification Report\nmodel.eval()\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images = images.to(device)\n        outputs = model(images)\n        _, preds = torch.max(outputs, 1)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.numpy())\n\ncm = confusion_matrix(all_labels, all_preds)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=class_names, yticklabels=class_names)\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.show()\n\nprint(\"\\nClassification Report:\\n\")\nprint(classification_report(all_labels, all_preds, target_names=class_names))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}